import cv2
import numpy as np
from typing import Optional, Tuple
from .screenshot_processor import ScreenshotProcessor
from .photo_processor import PhotoProcessor
from .utils import detect_text_orientation, detect_rotation_angle, rotate_image, four_point_transform
try:
    import pytesseract
except ImportError:
    pytesseract = None


class ImagePreprocessor:
    """
    Hlavn√≠ t≈ô√≠da pro p≈ôedzpracov√°n√≠ obr√°zk≈Ø p√≠sn√≠.

    Univerz√°ln√≠ p≈ô√≠stup:
    1. Pokus√≠ se naj√≠t oblast s p√≠sn√≠ (YOLO) nebo pap√≠r (edge detection)
    2. O≈ô√≠zne/vy≈ô√≠zne nalezenou oblast
    3. Aplikuje perspektivn√≠ transformaci pokud je detekov√°n pap√≠r
    4. Otoƒç√≠ text do spr√°vn√© orientace (horizont√°lnƒõ)
    5. Oprav√≠ drobnou rotaci
    6. Aplikuje grayscale + denoising
    """

    def __init__(self, yolo_model_path: str):
        """
        Inicializace preprocessoru.

        Args:
            yolo_model_path: Cesta k YOLO modelu pro detekci p√≠sn√≠
        """
        self.screenshot_processor = ScreenshotProcessor(yolo_model_path)
        self.photo_processor = PhotoProcessor()

    def preprocess(self, image_path: str, output_path: Optional[str] = None) -> list:
        """
        P≈ôedzpracuje obr√°zek - univerz√°ln√≠ logika pro v≈°echny typy.

        Najde v≈°echny p√≠snƒõ na obr√°zku a zpracuje ka≈ædou samostatnƒõ.

        Kroky:
        1. YOLO najde v≈°echny p√≠snƒõ na obr√°zku
        2. Pro ka≈ædou p√≠se≈à:
           a) Cropne oblast
           b) Zkus√≠ paper detection v okol√≠
           c) Aplikuje perspektivn√≠ transformaci pokud najde pap√≠r
           d) Otoƒç√≠ text do spr√°vn√© orientace
           e) Oprav√≠ rotaci
           f) Aplikuje grayscale + denoising
           g) Ulo≈æ√≠ jako samostatn√Ω soubor

        Args:
            image_path: Cesta k vstupn√≠mu obr√°zku
            output_path: Cesta k v√Ωstupn√≠mu souboru (voliteln√©, pro jednu p√≠se≈à)

        Returns:
            List cest k v√Ωstupn√≠m soubor≈Øm
        """
        # Naƒçten√≠ obr√°zku
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"Nepoda≈ôilo se naƒç√≠st obr√°zek: {image_path}")

        # KROK 1: YOLO detekce v≈°ech p√≠sn√≠
        detected_boxes = self.screenshot_processor.detect_all_songs(image_path, image)

        output_paths = []

        if len(detected_boxes) == 0:
            # YOLO nena≈°lo nic - zkus√≠me paper detection na cel√©m obr√°zku
            print("  ‚ö†Ô∏è  No songs detected by YOLO, trying paper detection...")
            paper_corners = self.photo_processor._detect_paper(image, debug=False)

            if paper_corners is not None:
                processed = four_point_transform(image, paper_corners)
            else:
                processed = image

            # Zpracuj jako jednu p√≠se≈à
            processed = self._process_single_song(processed)

            # Ulo≈æ
            final_output_path = self._save_processed(image_path, processed, output_path, song_index=None)
            output_paths.append(final_output_path)

        else:
            # Zpracuj ka≈ædou detekovanou p√≠se≈à
            print(f"  ‚úÖ Found {len(detected_boxes)} song(s)")

            for i, (x1, y1, x2, y2) in enumerate(detected_boxes):
                print(f"  üìù Processing song {i+1}/{len(detected_boxes)}...")

                # P≈ôid√°me padding
                h, w = image.shape[:2]
                padding_x = int((x2 - x1) * 0.05)
                padding_y = int((y2 - y1) * 0.05)

                x1 = max(0, x1 - padding_x)
                y1 = max(0, y1 - padding_y)
                x2 = min(w, x2 + padding_x)
                y2 = min(h, y2 + padding_y)

                # Crop
                cropped = image[y1:y2, x1:x2]

                # Zkus√≠me paper detection v cropnut√© oblasti
                paper_corners = self.photo_processor._detect_paper(cropped, debug=False)

                if paper_corners is not None:
                    print(f"     üìÑ Paper detected, applying perspective transform")
                    processed = four_point_transform(cropped, paper_corners)
                else:
                    processed = cropped

                # Zpracuj p√≠se≈à
                processed = self._process_single_song(processed)

                # Ulo≈æ
                song_output = output_path if len(detected_boxes) == 1 else None
                final_output_path = self._save_processed(image_path, processed, song_output, song_index=i+1)
                output_paths.append(final_output_path)

        return output_paths

    def _process_single_song(self, image: np.ndarray) -> np.ndarray:
        """
        Zpracuje jednu p√≠se≈à: rotace + denoising.

        Args:
            image: Vstupn√≠ obr√°zek

        Returns:
            Zpracovan√Ω obr√°zek
        """
        # KROK 1: Otoƒçit do spr√°vn√© orientace (90¬∞/180¬∞/270¬∞)
        orientation_angle = detect_text_orientation(image, debug=False)
        if orientation_angle != 0:
            image = rotate_image(image, -orientation_angle)

        # KROK 2: Opravit rotaci (Hough)
        angle = detect_rotation_angle(image)

        # Pokud je √∫hel vƒõt≈°√≠ ne≈æ 15¬∞, zkus√≠me v≈°echny orientace a vybereme nejlep≈°√≠
        if abs(angle) > 15:
            # Zkus√≠me 4 orientace a vybereme tu s nejmen≈°√≠m zbytkov√Ωm √∫hlem
            candidates = []

            # 0¬∞ (≈æ√°dn√° rotace)
            angle_0 = abs(detect_rotation_angle(image))
            candidates.append((0, angle_0, image))

            # 90¬∞ doleva
            rotated_90 = rotate_image(image, 90)
            angle_90 = abs(detect_rotation_angle(rotated_90))
            candidates.append((90, angle_90, rotated_90))

            # 90¬∞ doprava (-90¬∞)
            rotated_m90 = rotate_image(image, -90)
            angle_m90 = abs(detect_rotation_angle(rotated_m90))
            candidates.append((-90, angle_m90, rotated_m90))

            # 180¬∞
            rotated_180 = rotate_image(image, 180)
            angle_180 = abs(detect_rotation_angle(rotated_180))
            candidates.append((180, angle_180, rotated_180))

            # Vyber orientaci s nejmen≈°√≠m zbytkov√Ωm √∫hlem
            best_rotation, best_angle, best_image = min(candidates, key=lambda x: x[1])

            # Pokud je i nejlep≈°√≠ residual angle > 10¬∞, Hough nen√≠ spolehliv√Ω
            # Zkus√≠me OCR-based metodu
            if best_angle > 10 and pytesseract is not None:
                ocr_candidates = []
                for rotation, _, img in candidates:
                    score = self._ocr_text_score(img)
                    ocr_candidates.append((rotation, score, img))

                # Vyber orientaci s nejvy≈°≈°√≠m OCR score
                best_rotation, best_score, best_image = max(ocr_candidates, key=lambda x: x[1])
                image = best_image
                angle = detect_rotation_angle(image)
            else:
                image = best_image
                angle = detect_rotation_angle(image)

        # Pak aplikuj jemnou rotaci
        if abs(angle) > 0.5:
            image = rotate_image(image, angle)

        # KROK 3: Z√°kladn√≠ p≈ôedzpracov√°n√≠
        image = self._basic_preprocessing(image)

        return image

    def _save_processed(self, image_path: str, processed: np.ndarray, output_path: Optional[str], song_index: Optional[int]) -> str:
        """
        Ulo≈æ√≠ zpracovan√Ω obr√°zek.

        Args:
            image_path: Cesta k origin√°ln√≠mu obr√°zku
            processed: Zpracovan√Ω obr√°zek
            output_path: Voliteln√° v√Ωstupn√≠ cesta
            song_index: Index p√≠snƒõ (pokud jich je v√≠ce)

        Returns:
            Cesta k ulo≈æen√©mu souboru
        """
        if output_path is None:
            from pathlib import Path
            input_file = Path(image_path)
            temp_dir = Path(__file__).parent.parent / "temp"
            temp_dir.mkdir(exist_ok=True)

            if song_index is None:
                output_path = str(temp_dir / f"{input_file.stem}_processed.png")
            else:
                output_path = str(temp_dir / f"{input_file.stem}_song{song_index}_processed.png")

        cv2.imwrite(output_path, processed)
        return output_path

    def _ocr_text_score(self, image: np.ndarray) -> float:
        """
        Spust√≠ rychl√© OCR a vr√°t√≠ sk√≥re (poƒçet detekovan√Ωch znak≈Ø).
        Vy≈°≈°√≠ sk√≥re = v√≠ce textu nalezeno = pravdƒõpodobnƒõ spr√°vn√° orientace.

        Args:
            image: Vstupn√≠ obr√°zek

        Returns:
            Sk√≥re (poƒçet alfanumerick√Ωch znak≈Ø)
        """
        if pytesseract is None:
            return 0.0

        try:
            # P≈ôevod na grayscale pokud je pot≈ôeba
            if len(image.shape) == 3:
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            else:
                gray = image

            # Aplikuj denoising pro lep≈°√≠ OCR
            denoised = cv2.fastNlMeansDenoising(gray, None, h=10, templateWindowSize=7, searchWindowSize=21)

            # Resize pokud je obr√°zek p≈ô√≠li≈° mal√Ω (OCR funguje l√©pe na vƒõt≈°√≠ch obr√°zc√≠ch)
            h, w = denoised.shape
            if h < 300:
                scale = 300 / h
                denoised = cv2.resize(denoised, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)

            # Rychl√© OCR s minim√°ln√≠ konfigurac√≠
            text = pytesseract.image_to_string(denoised, config='--psm 6 --oem 1')

            # Spoƒç√≠tej alfanumerick√© znaky (ignoruj whitespace)
            alnum_count = sum(c.isalnum() for c in text)

            return float(alnum_count)

        except Exception:
            return 0.0

    def _basic_preprocessing(self, image: np.ndarray) -> np.ndarray:
        """
        Z√°kladn√≠ p≈ôedzpracov√°n√≠ - v≈ædy stejn√©:
        1. Grayscale
        2. Denoising
        3. BEZ threshold (zachov√° odst√≠ny ≈°edi)

        Args:
            image: Vstupn√≠ obr√°zek

        Returns:
            P≈ôedzpracovan√Ω obr√°zek (grayscale s denoisingem)
        """
        # 1. P≈ôevod na grayscale
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image

        # 2. Odstranƒõn√≠ ≈°umu
        denoised = cv2.fastNlMeansDenoising(gray, None, h=10, templateWindowSize=7, searchWindowSize=21)

        # 3. BEZ threshold - vr√°t√≠me grayscale s denoisingem
        return denoised
