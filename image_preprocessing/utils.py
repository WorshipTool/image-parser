import cv2
import numpy as np
from enum import Enum
import os
try:
    import pytesseract
except ImportError:
    pytesseract = None


class ImageType(Enum):
    """Typ vstupnÃ­ho obrÃ¡zku"""
    SCREENSHOT = "screenshot"
    PHOTO = "photo"
    SCAN = "scan"


def detect_image_type(image: np.ndarray, image_path: str = None) -> ImageType:
    """
    Detekuje typ obrÃ¡zku (screenshot, photo, scan).

    Heuristiky:
    - Screenshot: obvykle mÃ¡ ostrÃ½ text, vysokÃ½ kontrast, Å¾Ã¡dnÃ© perspektivnÃ­ zkreslenÃ­
    - Photo: mÅ¯Å¾e bÃ½t rozmazanÃ½, mÃ¡ perspektivnÃ­ zkreslenÃ­, rÅ¯znÃ© osvÄ›tlenÃ­
    - Scan: vysoce kvalitnÃ­, rovnÃ½, Äasto mÃ¡ ÄernÃ½ okraj

    Args:
        image: VstupnÃ­ obrÃ¡zek
        image_path: Cesta k obrÃ¡zku (pouÅ¾ije se pro detekci podle nÃ¡zvu sloÅ¾ky)

    Returns:
        Typ obrÃ¡zku
    """
    # Pokud je cesta k obrÃ¡zku, zkusÃ­me detekci podle sloÅ¾ky
    if image_path:
        path_lower = image_path.lower()
        if 'screenshot' in path_lower:
            return ImageType.SCREENSHOT
        elif 'photo' in path_lower:
            return ImageType.PHOTO
        elif 'scan' in path_lower:
            return ImageType.SCAN

    # HeuristickÃ¡ detekce podle vlastnostÃ­ obrÃ¡zku
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image

    # VÃ½poÄet Laplacian variance (mÃ­ra ostrosti)
    laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()

    # Screenshots majÃ­ obvykle velmi ostrÃ½ text
    if laplacian_var > 1000:
        return ImageType.SCREENSHOT

    # Detekce okrajÅ¯ pro identifikaci papÃ­ru (photos)
    edges = cv2.Canny(gray, 50, 150)
    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # Pokud najdeme velkÃ½ ÄtyÅ™ÃºhelnÃ­k, pravdÄ›podobnÄ› jde o fotku papÃ­ru
    if len(contours) > 0:
        largest_contour = max(contours, key=cv2.contourArea)
        area = cv2.contourArea(largest_contour)
        image_area = image.shape[0] * image.shape[1]

        # Pokud nejvÄ›tÅ¡Ã­ kontura zabÃ­rÃ¡ 30-95% obrÃ¡zku, mÅ¯Å¾e jÃ­t o papÃ­r na fotce
        if 0.3 < area / image_area < 0.95:
            peri = cv2.arcLength(largest_contour, True)
            approx = cv2.approxPolyDP(largest_contour, 0.02 * peri, True)
            if len(approx) == 4:
                return ImageType.PHOTO

    # VÃ½chozÃ­: SCAN
    return ImageType.SCAN


def order_points(pts: np.ndarray) -> np.ndarray:
    """
    SeÅ™adÃ­ 4 body ÄtyÅ™ÃºhelnÃ­ku v poÅ™adÃ­: top-left, top-right, bottom-right, bottom-left.

    Args:
        pts: Array 4 bodÅ¯ tvaru (4, 2)

    Returns:
        SeÅ™azenÃ© body
    """
    rect = np.zeros((4, 2), dtype="float32")

    # Top-left mÃ¡ nejmenÅ¡Ã­ souÄet, bottom-right nejvÄ›tÅ¡Ã­
    s = pts.sum(axis=1)
    rect[0] = pts[np.argmin(s)]
    rect[2] = pts[np.argmax(s)]

    # Top-right mÃ¡ nejmenÅ¡Ã­ rozdÃ­l, bottom-left nejvÄ›tÅ¡Ã­
    diff = np.diff(pts, axis=1)
    rect[1] = pts[np.argmin(diff)]
    rect[3] = pts[np.argmax(diff)]

    return rect


def four_point_transform(image: np.ndarray, pts: np.ndarray) -> np.ndarray:
    """
    Provede perspektivnÃ­ transformaci na zÃ¡kladÄ› 4 bodÅ¯.

    Args:
        image: VstupnÃ­ obrÃ¡zek
        pts: 4 body definujÃ­cÃ­ ÄtyÅ™ÃºhelnÃ­k

    Returns:
        TransformovanÃ½ obrÃ¡zek (pohled shora)
    """
    rect = order_points(pts)
    (tl, tr, br, bl) = rect

    # VÃ½poÄet Å¡Ã­Å™ky vÃ½stupnÃ­ho obrÃ¡zku
    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))
    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))
    maxWidth = max(int(widthA), int(widthB))

    # VÃ½poÄet vÃ½Å¡ky vÃ½stupnÃ­ho obrÃ¡zku
    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))
    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))
    maxHeight = max(int(heightA), int(heightB))

    # CÃ­lovÃ© body pro transformaci
    dst = np.array([
        [0, 0],
        [maxWidth - 1, 0],
        [maxWidth - 1, maxHeight - 1],
        [0, maxHeight - 1]
    ], dtype="float32")

    # VÃ½poÄet perspektivnÃ­ transformace
    M = cv2.getPerspectiveTransform(rect, dst)
    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))

    return warped


def rotate_image(image: np.ndarray, angle: float) -> np.ndarray:
    """
    OtoÄÃ­ obrÃ¡zek o danÃ½ Ãºhel.

    Args:
        image: VstupnÃ­ obrÃ¡zek
        angle: Ãšhel v stupnÃ­ch (kladnÃ½ = proti smÄ›ru hodinovÃ½ch ruÄiÄek)

    Returns:
        OtoÄenÃ½ obrÃ¡zek
    """
    (h, w) = image.shape[:2]
    center = (w // 2, h // 2)

    # VytvoÅ™enÃ­ rotaÄnÃ­ matice
    M = cv2.getRotationMatrix2D(center, angle, 1.0)

    # VÃ½poÄet novÃ½ch rozmÄ›rÅ¯
    cos = np.abs(M[0, 0])
    sin = np.abs(M[0, 1])
    new_w = int((h * sin) + (w * cos))
    new_h = int((h * cos) + (w * sin))

    # Ãšprava translace
    M[0, 2] += (new_w / 2) - center[0]
    M[1, 2] += (new_h / 2) - center[1]

    # Rotace
    rotated = cv2.warpAffine(image, M, (new_w, new_h),
                             flags=cv2.INTER_CUBIC,
                             borderMode=cv2.BORDER_CONSTANT,
                             borderValue=(255, 255, 255))

    return rotated


def detect_rotation_angle(image: np.ndarray) -> float:
    """
    Detekuje Ãºhel rotace textu v obrÃ¡zku pomocÃ­ Hough transform.

    Args:
        image: VstupnÃ­ obrÃ¡zek (grayscale)

    Returns:
        Ãšhel rotace ve stupnÃ­ch
    """
    # Pokud je obrÃ¡zek barevnÃ½, pÅ™evedeme na grayscale
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image

    # Detekce hran
    edges = cv2.Canny(gray, 50, 150, apertureSize=3)

    # Hough Line Transform
    lines = cv2.HoughLines(edges, 1, np.pi / 180, 200)

    if lines is None or len(lines) == 0:
        return 0.0

    # VÃ½poÄet prÅ¯mÄ›rnÃ©ho Ãºhlu
    angles = []
    for rho, theta in lines[:, 0]:
        angle = (theta * 180 / np.pi) - 90
        # Filtrujeme pouze Ãºhly blÃ­zko horizontÃ¡ly
        if -45 < angle < 45:
            angles.append(angle)

    if len(angles) == 0:
        return 0.0

    # MediÃ¡n ÃºhlÅ¯ (robustnÄ›jÅ¡Ã­ neÅ¾ prÅ¯mÄ›r)
    median_angle = np.median(angles)
    return median_angle


def detect_text_orientation(image: np.ndarray, debug: bool = False) -> int:
    """
    Detekuje orientaci textu v obrÃ¡zku pomocÃ­ Tesseract OSD.

    Args:
        image: VstupnÃ­ obrÃ¡zek
        debug: Pokud True, vypÃ­Å¡e debug informace

    Returns:
        Ãšhel rotace potÅ™ebnÃ½ k narovnÃ¡nÃ­ textu (0, 90, 180, 270)
    """
    # PÅ™evod na grayscale pokud je potÅ™eba
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image

    h, w = gray.shape[:2]

    if debug:
        print(f"  ğŸ” Image dimensions: {w}x{h} (aspect ratio: {w/h:.2f})")

    if pytesseract is None:
        # Fallback: heuristika zaloÅ¾enÃ¡ na aspect ratio
        if h > w * 1.3:  # Pokud je vÃ½raznÄ› vyÅ¡Å¡Ã­ neÅ¾ Å¡irÅ¡Ã­
            if debug:
                print(f"  âš ï¸  No pytesseract, using heuristic: rotate 270Â° (or -90Â°)")
            return 270  # OtoÄit o 270Â° = -90Â° = doprava po smÄ›ru hodinovÃ½ch ruÄiÄek
        return 0

    try:
        # Tesseract OSD (Orientation and Script Detection)
        # --psm 0 = pouze OSD, Å¾Ã¡dnÃ© OCR
        use_fallback = False

        try:
            osd = pytesseract.image_to_osd(gray)

            if debug:
                print(f"  ğŸ“„ Tesseract OSD output:")
                for line in osd.split('\n'):
                    if line.strip():
                        print(f"     {line}")

            # Parse vÃ½stupu
            rotation_angle = 0
            orientation_conf = 0
            for line in osd.split('\n'):
                if 'Rotate:' in line:
                    rotation_angle = int(line.split(':')[1].strip())
                if 'Orientation confidence:' in line:
                    orientation_conf = float(line.split(':')[1].strip())

            if debug:
                print(f"  ğŸ”„ Detected rotation: {rotation_angle}Â° (confidence: {orientation_conf:.1f})")

            # Pouze pokud je confidence dostateÄnÄ› vysokÃ¡ (min 1.5), pouÅ¾ijeme Tesseract vÃ½sledek
            if orientation_conf >= 1.5:
                return rotation_angle
            else:
                if debug:
                    print(f"  âš ï¸  Confidence too low ({orientation_conf:.1f} < 1.5), using Hough fallback")
                use_fallback = True

        except Exception as e:
            if debug:
                print(f"  âš ï¸  Tesseract OSD failed: {e}")
            use_fallback = True

        # Fallback: PouÅ¾ijeme Hough detekci liniÃ­ k urÄenÃ­ orientace
        # (provede se kdyÅ¾ Tesseract selÅ¾e NEBO mÃ¡ nÃ­zkou confidence)
        if use_fallback:
            edges = cv2.Canny(gray, 50, 150, apertureSize=3)
            lines = cv2.HoughLines(edges, 1, np.pi / 180, 100)

            if lines is not None and len(lines) > 5:
                # SpoÄÃ­tÃ¡me horizontÃ¡lnÃ­ vs vertikÃ¡lnÃ­ linie
                horizontal_count = 0
                vertical_count = 0

                for rho, theta in lines[:, 0]:
                    angle_deg = (theta * 180 / np.pi)

                    # HorizontÃ¡lnÃ­ linie: kolem 0Â° nebo 180Â°
                    if (angle_deg < 20 or angle_deg > 160):
                        horizontal_count += 1
                    # VertikÃ¡lnÃ­ linie: kolem 90Â°
                    elif (70 < angle_deg < 110):
                        vertical_count += 1

                if debug:
                    print(f"  ğŸ“ Line detection: {horizontal_count} horizontal, {vertical_count} vertical")

                # Pokud je vÃ­c vertikÃ¡lnÃ­ch neÅ¾ horizontÃ¡lnÃ­ch, text je otoÄenÃ½ o 90Â°
                # PouÅ¾ijeme niÅ¾Å¡Ã­ threshold (1.2x mÃ­sto 1.5x) pro lepÅ¡Ã­ detekci
                if vertical_count > horizontal_count * 1.2:
                    if debug:
                        print(f"  ğŸ“ Detected vertical text, rotating 270Â° (or -90Â°)")
                    return 270

            # PoslednÃ­ fallback: aspect ratio
            if h > w * 1.3:
                if debug:
                    print(f"  ğŸ“ Using aspect ratio heuristic (h>w*1.3): rotate 270Â° (or -90Â°)")
                return 270

            if debug:
                print(f"  ğŸ“ No clear orientation detected, keeping 0Â°")
            return 0

    except Exception as e:
        if debug:
            print(f"  âŒ Error: {e}")
        # Fallback: Å¾Ã¡dnÃ¡ rotace
        return 0
