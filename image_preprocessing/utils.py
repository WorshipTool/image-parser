import cv2
import numpy as np
from enum import Enum
import os
try:
    import pytesseract
except ImportError:
    pytesseract = None


class ImageType(Enum):
    """Typ vstupn√≠ho obr√°zku"""
    SCREENSHOT = "screenshot"
    PHOTO = "photo"
    SCAN = "scan"


def detect_image_type(image: np.ndarray, image_path: str = None) -> ImageType:
    """
    Detekuje typ obr√°zku (screenshot, photo, scan).

    Heuristiky:
    - Screenshot: obvykle m√° ostr√Ω text, vysok√Ω kontrast, ≈æ√°dn√© perspektivn√≠ zkreslen√≠
    - Photo: m≈Ø≈æe b√Ωt rozmazan√Ω, m√° perspektivn√≠ zkreslen√≠, r≈Øzn√© osvƒõtlen√≠
    - Scan: vysoce kvalitn√≠, rovn√Ω, ƒçasto m√° ƒçern√Ω okraj

    Args:
        image: Vstupn√≠ obr√°zek
        image_path: Cesta k obr√°zku (pou≈æije se pro detekci podle n√°zvu slo≈æky)

    Returns:
        Typ obr√°zku
    """
    # Pokud je cesta k obr√°zku, zkus√≠me detekci podle slo≈æky
    if image_path:
        path_lower = image_path.lower()
        if 'screenshot' in path_lower:
            return ImageType.SCREENSHOT
        elif 'photo' in path_lower:
            return ImageType.PHOTO
        elif 'scan' in path_lower:
            return ImageType.SCAN

    # Heuristick√° detekce podle vlastnost√≠ obr√°zku
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) if len(image.shape) == 3 else image

    # V√Ωpoƒçet Laplacian variance (m√≠ra ostrosti)
    laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()

    # Screenshots maj√≠ obvykle velmi ostr√Ω text
    if laplacian_var > 1000:
        return ImageType.SCREENSHOT

    # Detekce okraj≈Ø pro identifikaci pap√≠ru (photos)
    edges = cv2.Canny(gray, 50, 150)
    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # Pokud najdeme velk√Ω ƒçty≈ô√∫heln√≠k, pravdƒõpodobnƒõ jde o fotku pap√≠ru
    if len(contours) > 0:
        largest_contour = max(contours, key=cv2.contourArea)
        area = cv2.contourArea(largest_contour)
        image_area = image.shape[0] * image.shape[1]

        # Pokud nejvƒõt≈°√≠ kontura zab√≠r√° 30-95% obr√°zku, m≈Ø≈æe j√≠t o pap√≠r na fotce
        if 0.3 < area / image_area < 0.95:
            peri = cv2.arcLength(largest_contour, True)
            approx = cv2.approxPolyDP(largest_contour, 0.02 * peri, True)
            if len(approx) == 4:
                return ImageType.PHOTO

    # V√Ωchoz√≠: SCAN
    return ImageType.SCAN


def order_points(pts: np.ndarray) -> np.ndarray:
    """
    Se≈ôad√≠ 4 body ƒçty≈ô√∫heln√≠ku v po≈ôad√≠: top-left, top-right, bottom-right, bottom-left.

    Args:
        pts: Array 4 bod≈Ø tvaru (4, 2)

    Returns:
        Se≈ôazen√© body
    """
    rect = np.zeros((4, 2), dtype="float32")

    # Top-left m√° nejmen≈°√≠ souƒçet, bottom-right nejvƒõt≈°√≠
    s = pts.sum(axis=1)
    rect[0] = pts[np.argmin(s)]
    rect[2] = pts[np.argmax(s)]

    # Top-right m√° nejmen≈°√≠ rozd√≠l, bottom-left nejvƒõt≈°√≠
    diff = np.diff(pts, axis=1)
    rect[1] = pts[np.argmin(diff)]
    rect[3] = pts[np.argmax(diff)]

    return rect


def four_point_transform(image: np.ndarray, pts: np.ndarray) -> np.ndarray:
    """
    Provede perspektivn√≠ transformaci na z√°kladƒõ 4 bod≈Ø.

    Args:
        image: Vstupn√≠ obr√°zek
        pts: 4 body definuj√≠c√≠ ƒçty≈ô√∫heln√≠k

    Returns:
        Transformovan√Ω obr√°zek (pohled shora)
    """
    rect = order_points(pts)
    (tl, tr, br, bl) = rect

    # V√Ωpoƒçet ≈°√≠≈ôky v√Ωstupn√≠ho obr√°zku
    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))
    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))
    maxWidth = max(int(widthA), int(widthB))

    # V√Ωpoƒçet v√Ω≈°ky v√Ωstupn√≠ho obr√°zku
    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))
    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))
    maxHeight = max(int(heightA), int(heightB))

    # C√≠lov√© body pro transformaci
    dst = np.array([
        [0, 0],
        [maxWidth - 1, 0],
        [maxWidth - 1, maxHeight - 1],
        [0, maxHeight - 1]
    ], dtype="float32")

    # V√Ωpoƒçet perspektivn√≠ transformace
    M = cv2.getPerspectiveTransform(rect, dst)
    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))

    return warped


def rotate_image(image: np.ndarray, angle: float) -> np.ndarray:
    """
    Otoƒç√≠ obr√°zek o dan√Ω √∫hel.

    Args:
        image: Vstupn√≠ obr√°zek
        angle: √öhel v stupn√≠ch (kladn√Ω = proti smƒõru hodinov√Ωch ruƒçiƒçek)

    Returns:
        Otoƒçen√Ω obr√°zek
    """
    (h, w) = image.shape[:2]
    center = (w // 2, h // 2)

    # Vytvo≈ôen√≠ rotaƒçn√≠ matice
    M = cv2.getRotationMatrix2D(center, angle, 1.0)

    # V√Ωpoƒçet nov√Ωch rozmƒõr≈Ø
    cos = np.abs(M[0, 0])
    sin = np.abs(M[0, 1])
    new_w = int((h * sin) + (w * cos))
    new_h = int((h * cos) + (w * sin))

    # √öprava translace
    M[0, 2] += (new_w / 2) - center[0]
    M[1, 2] += (new_h / 2) - center[1]

    # Rotace
    rotated = cv2.warpAffine(image, M, (new_w, new_h),
                             flags=cv2.INTER_CUBIC,
                             borderMode=cv2.BORDER_CONSTANT,
                             borderValue=(255, 255, 255))

    return rotated


def detect_rotation_angle(image: np.ndarray) -> float:
    """
    Detekuje √∫hel rotace textu v obr√°zku pomoc√≠ Hough transform.

    Args:
        image: Vstupn√≠ obr√°zek (grayscale)

    Returns:
        √öhel rotace ve stupn√≠ch
    """
    # Pokud je obr√°zek barevn√Ω, p≈ôevedeme na grayscale
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image

    # Detekce hran
    edges = cv2.Canny(gray, 50, 150, apertureSize=3)

    # Hough Line Transform
    lines = cv2.HoughLines(edges, 1, np.pi / 180, 200)

    if lines is None or len(lines) == 0:
        return 0.0

    # V√Ωpoƒçet pr≈Ømƒõrn√©ho √∫hlu
    angles = []
    for rho, theta in lines[:, 0]:
        angle = (theta * 180 / np.pi) - 90
        # Filtrujeme pouze √∫hly bl√≠zko horizont√°ly
        if -45 < angle < 45:
            angles.append(angle)

    if len(angles) == 0:
        return 0.0

    # Medi√°n √∫hl≈Ø (robustnƒõj≈°√≠ ne≈æ pr≈Ømƒõr)
    median_angle = np.median(angles)
    return median_angle


def detect_text_orientation(image: np.ndarray, debug: bool = False) -> int:
    """
    Detekuje orientaci textu v obr√°zku pomoc√≠ Tesseract OSD.

    Args:
        image: Vstupn√≠ obr√°zek
        debug: Pokud True, vyp√≠≈°e debug informace

    Returns:
        √öhel rotace pot≈ôebn√Ω k narovn√°n√≠ textu (0, 90, 180, 270)
    """
    # P≈ôevod na grayscale pokud je pot≈ôeba
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image

    h, w = gray.shape[:2]

    if debug:
        print(f"  üîç Image dimensions: {w}x{h} (aspect ratio: {w/h:.2f})")

    if pytesseract is None:
        # Fallback: heuristika zalo≈æen√° na aspect ratio
        if h > w * 1.3:  # Pokud je v√Ωraznƒõ vy≈°≈°√≠ ne≈æ ≈°ir≈°√≠
            if debug:
                print(f"  ‚ö†Ô∏è  No pytesseract, using heuristic: rotate 270¬∞ (or -90¬∞)")
            return 270  # Otoƒçit o 270¬∞ = -90¬∞ = doprava po smƒõru hodinov√Ωch ruƒçiƒçek
        return 0

    try:
        # Tesseract OSD (Orientation and Script Detection)
        # --psm 0 = pouze OSD, ≈æ√°dn√© OCR
        try:
            osd = pytesseract.image_to_osd(gray)

            if debug:
                print(f"  üìÑ Tesseract OSD output:")
                for line in osd.split('\n'):
                    if line.strip():
                        print(f"     {line}")

            # Parse v√Ωstupu
            rotation_angle = 0
            orientation_conf = 0
            for line in osd.split('\n'):
                if 'Rotate:' in line:
                    rotation_angle = int(line.split(':')[1].strip())
                if 'Orientation confidence:' in line:
                    orientation_conf = float(line.split(':')[1].strip())

            if debug:
                print(f"  üîÑ Detected rotation: {rotation_angle}¬∞ (confidence: {orientation_conf:.1f})")

            return rotation_angle

        except Exception as e:
            if debug:
                print(f"  ‚ö†Ô∏è  Tesseract OSD failed: {e}")
            # Pokud OSD sel≈æe, zkus√≠me heuristiku
            if h > w * 1.3:
                if debug:
                    print(f"  üìê Using heuristic (h>w*1.3): rotate 270¬∞ (or -90¬∞)")
                return 270
            return 0

    except Exception as e:
        if debug:
            print(f"  ‚ùå Error: {e}")
        # Fallback: ≈æ√°dn√° rotace
        return 0
