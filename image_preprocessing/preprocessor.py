import cv2
import numpy as np
from typing import Optional, List
from pathlib import Path
from ultralytics import YOLO
from .utils import detect_text_orientation, detect_rotation_angle, rotate_image


class ImagePreprocessor:
    """
    Hlavn√≠ t≈ô√≠da pro p≈ôedzpracov√°n√≠ obr√°zk≈Ø p√≠sn√≠.

    Zjednodu≈°en√Ω univerz√°ln√≠ p≈ô√≠stup:
    1. YOLO najde v≈°echny p√≠snƒõ na obr√°zku
    2. Pro ka≈ædou p√≠se≈à:
       - Crop s paddingem
       - Detekce orientace + rotace (Tesseract OSD + Hough fallback)
       - Hough rotaƒçn√≠ korekce
       - Grayscale + denoising
    """

    def __init__(self, yolo_model_path: str):
        """
        Inicializace preprocessoru.

        Args:
            yolo_model_path: Cesta k YOLO modelu pro detekci p√≠sn√≠
        """
        self.model = YOLO(yolo_model_path)

    def preprocess(self, image_path: str, output_path: Optional[str] = None) -> List[str]:
        """
        P≈ôedzpracuje obr√°zek - najde v≈°echny p√≠snƒõ a zpracuje je.

        Args:
            image_path: Cesta k vstupn√≠mu obr√°zku
            output_path: Cesta k v√Ωstupn√≠mu souboru (voliteln√©, pro jednu p√≠se≈à)

        Returns:
            List cest k v√Ωstupn√≠m soubor≈Øm
        """
        # Naƒçten√≠ obr√°zku
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"Nepoda≈ôilo se naƒç√≠st obr√°zek: {image_path}")

        # YOLO detekce v≈°ech p√≠sn√≠
        detected_boxes = self._detect_all_songs(image_path, image)
        output_paths = []

        if len(detected_boxes) == 0:
            # YOLO nena≈°lo nic - zpracuj cel√Ω obr√°zek
            print("  ‚ö†Ô∏è  No songs detected by YOLO, processing whole image...")
            processed = self._process_single_song(image)
            final_output_path = self._save_processed(image_path, processed, output_path, song_index=None)
            output_paths.append(final_output_path)
        else:
            # Zpracuj ka≈ædou detekovanou p√≠se≈à
            print(f"  ‚úÖ Found {len(detected_boxes)} song(s)")

            for i, (x1, y1, x2, y2) in enumerate(detected_boxes):
                print(f"  üìù Processing song {i+1}/{len(detected_boxes)}...")

                # YOLO crop s paddingem (5%)
                h, w = image.shape[:2]
                padding_x = int((x2 - x1) * 0.05)
                padding_y = int((y2 - y1) * 0.05)

                x1_crop = max(0, x1 - padding_x)
                y1_crop = max(0, y1 - padding_y)
                x2_crop = min(w, x2 + padding_x)
                y2_crop = min(h, y2 + padding_y)

                cropped = image[y1_crop:y2_crop, x1_crop:x2_crop]

                # Zpracuj p√≠se≈à (rotace + denoising)
                processed = self._process_single_song(cropped)

                # Ulo≈æ
                song_output = output_path if len(detected_boxes) == 1 else None
                final_output_path = self._save_processed(image_path, processed, song_output, song_index=i+1)
                output_paths.append(final_output_path)

        return output_paths

    def _detect_all_songs(self, image_path: str, image: np.ndarray) -> List[tuple]:
        """
        Detekuje v≈°echny p√≠snƒõ na obr√°zku pomoc√≠ YOLO.

        Args:
            image_path: Cesta k obr√°zku (pro YOLO)
            image: Naƒçten√Ω obr√°zek (pro kontrolu rozmƒõr≈Ø)

        Returns:
            List bounding box≈Ø [(x1, y1, x2, y2), ...]
        """
        results = self.model.predict(image_path, conf=0.25, verbose=False)

        if len(results) == 0 or len(results[0].boxes) == 0:
            return []

        boxes = results[0].boxes
        detected_boxes = []

        for box in boxes:
            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
            detected_boxes.append((int(x1), int(y1), int(x2), int(y2)))

        # Se≈ôaƒè podle velikosti (nejvƒõt≈°√≠ prvn√≠)
        detected_boxes.sort(key=lambda b: (b[2]-b[0])*(b[3]-b[1]), reverse=True)

        return detected_boxes

    def _process_single_song(self, image: np.ndarray) -> np.ndarray:
        """
        Zpracuje jednu p√≠se≈à: rotace + denoising.

        Args:
            image: Vstupn√≠ obr√°zek

        Returns:
            Zpracovan√Ω obr√°zek
        """
        # KROK 1: Otoƒçit do spr√°vn√© orientace (90¬∞/180¬∞/270¬∞)
        orientation_angle = detect_text_orientation(image, debug=False)
        if orientation_angle != 0:
            image = rotate_image(image, -orientation_angle)

        # KROK 2: Opravit rotaci (text-based detection)
        angle = detect_rotation_angle(image, debug=True)

        # Jemn√° rotace (neguj √∫hel, proto≈æe rotace je ve smƒõru hodinov√Ωch ruƒçiƒçek)
        if abs(angle) > 0.5:
            image = rotate_image(image, -angle)

        # KROK 3: Z√°kladn√≠ p≈ôedzpracov√°n√≠
        image = self._basic_preprocessing(image)

        return image

    def _save_processed(self, image_path: str, processed: np.ndarray, output_path: Optional[str], song_index: Optional[int]) -> str:
        """
        Ulo≈æ√≠ zpracovan√Ω obr√°zek.

        Args:
            image_path: Cesta k origin√°ln√≠mu obr√°zku
            processed: Zpracovan√Ω obr√°zek
            output_path: Voliteln√° v√Ωstupn√≠ cesta
            song_index: Index p√≠snƒõ (pokud jich je v√≠ce)

        Returns:
            Cesta k ulo≈æen√©mu souboru
        """
        if output_path is None:
            input_file = Path(image_path)
            temp_dir = Path(__file__).parent.parent / "temp"
            temp_dir.mkdir(exist_ok=True)

            if song_index is None:
                output_path = str(temp_dir / f"{input_file.stem}_processed.png")
            else:
                output_path = str(temp_dir / f"{input_file.stem}_song{song_index}_processed.png")

        cv2.imwrite(output_path, processed)
        return output_path

    def _basic_preprocessing(self, image: np.ndarray) -> np.ndarray:
        """
        Z√°kladn√≠ p≈ôedzpracov√°n√≠:
        1. Grayscale
        2. Denoising
        3. BEZ threshold (zachov√° odst√≠ny ≈°edi)

        Args:
            image: Vstupn√≠ obr√°zek

        Returns:
            P≈ôedzpracovan√Ω obr√°zek (grayscale s denoisingem)
        """
        # 1. P≈ôevod na grayscale
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image

        # 2. Odstranƒõn√≠ ≈°umu
        denoised = cv2.fastNlMeansDenoising(gray, None, h=10, templateWindowSize=7, searchWindowSize=21)

        # 3. BEZ threshold - vr√°t√≠me grayscale s denoisingem
        return denoised
